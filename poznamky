

https://www.aclweb.org/anthology/W16-3649.pdf




https://www.aclweb.org/anthology/I17-5003.pdf
4 Social Chat Bots
Social bots are of growing importance in facilitating smooth interaction between humans and
their electronic devices. Recently, researcher have
begun to explore data-driven generation of conversational responses within the framework of
nerual machine translation (NMT) in the form
of encoder-decoder or seq2seq models (Sordoni
et al., 2015; Vinyals and Le, 2015; Li et al.,
2016a), as illustrated in Figure 2.
However, the generated responses are often too
general to carry meaningful information, such as
“I don’t know.”, which can serve as a response to
any user questions. A mutual information based
model was proposed to address the issue, a mutual information model is proposed by Li et al.
(2016a), and is later improved by using deep reinforcement learning (Li et al., 2016c). Furthermore, Li et al. (2016b) presented a persona-based
model to address the issue of speaker consistency
in neural response generation.
Although task-oriented dialogue systems and
social bots are originally developed for different
purposes, there is a trend of combining both as
a step towards building an open-domain dialogue
agent.
For example, on the one hand, Ghazvininejad
et al. (2017) presented a fully data-driven and
knowledge-grounded neural conversation model
aimed at producing more contentful responses
without slot filling. On the other hand, Zhao et al.
(2017) proposed a task-oriented dialogue agented
based on the encoder-decoder model with chatting
capability.

A neural network language model is a language model based on Neural Networks , exploiting their ability to learn distributed representations to reduce the impact of the curse of dimensionality.

http://jalammar.github.io/illustrated-transformer/

https://www.geeksforgeeks.org/seq2seq-model-in-machine-learning/

Previous work:

There are a variety of methods to generate responses for nontask-oriented systems, such as machine translation
(Ritter et al., 2011), retrieval-based response selection (Banchs and Li, 2012), and sequence-tosequence recurrent neural network (Vinyals and
Le, 2015). However, these systems still produce utterances that are incoherent or inappropriate from time to time. 

https://www.sciencedirect.com/science/article/pii/S0885230819300919  This paper provides a comprehensive final report and extended analysis of the first shared task on End-to-End (E2E) Natural Language Generation (NLG), substantially extending previous reports (Novikova, Rieser, 2016, Novikova, Dušek, Rieser, 2017b, Dušek, Novikova, Rieser, 2018). 



Shang et al.(2015)  propose a Neural Responding Machine (NRM), a neural network-based
chatbot NLG for Short-Text Conversation, which is trained on a large amount of one-round conversation data collected from a microblogging service


 https://www.aclweb.org/anthology/N18-2010.pdf Previous work proposed
an RNNLM-based NLG (Wen et al., 2015) that
can be trained on any corpus of dialogue actutterance pairs without any semantic alignment
and hand-crafted features. Sequence-to-sequence
(seq2seq) generators (Cho et al., 2014; Sutskever
et al., 2014) further offer better results by leveraging encoder-decoder structure: previous model
encoded syntax trees and dialogue acts into sequences (Dusek and Jur ˇ cˇ´ıcek ˇ , 2016) as inputs of


http://primo.ai/index.php?title=Transformer


architektura: 
emotional decoder 
https://link.springer.com/chapter/10.1007/978-3-319-73618-1_51
attentional seq2seq model (Bahdanau et al., 2015).



https://www.aclweb.org/anthology/W16-3649.pdf




https://www.aclweb.org/anthology/I17-5003.pdf
4 Social Chat Bots
Social bots are of growing importance in facilitating smooth interaction between humans and
their electronic devices. Recently, researcher have
begun to explore data-driven generation of conversational responses within the framework of
nerual machine translation (NMT) in the form
of encoder-decoder or seq2seq models (Sordoni
et al., 2015; Vinyals and Le, 2015; Li et al.,
2016a), as illustrated in Figure 2.
However, the generated responses are often too
general to carry meaningful information, such as
“I don’t know.”, which can serve as a response to
any user questions. A mutual information based
model was proposed to address the issue, a mutual information model is proposed by Li et al.
(2016a), and is later improved by using deep reinforcement learning (Li et al., 2016c). Furthermore, Li et al. (2016b) presented a persona-based
model to address the issue of speaker consistency
in neural response generation.
Although task-oriented dialogue systems and
social bots are originally developed for different
purposes, there is a trend of combining both as
a step towards building an open-domain dialogue
agent.
For example, on the one hand, Ghazvininejad
et al. (2017) presented a fully data-driven and
knowledge-grounded neural conversation model
aimed at producing more contentful responses
without slot filling. On the other hand, Zhao et al.
(2017) proposed a task-oriented dialogue agented
based on the encoder-decoder model with chatting
capability.

A neural network language model is a language model based on Neural Networks , exploiting their ability to learn distributed representations to reduce the impact of the curse of dimensionality.

http://jalammar.github.io/illustrated-transformer/

https://www.geeksforgeeks.org/seq2seq-model-in-machine-learning/

Previous work:

There are a variety of methods to generate responses for nontask-oriented systems, such as machine translation
(Ritter et al., 2011), retrieval-based response selection (Banchs and Li, 2012), and sequence-tosequence recurrent neural network (Vinyals and
Le, 2015). However, these systems still produce utterances that are incoherent or inappropriate from time to time. 

https://www.sciencedirect.com/science/article/pii/S0885230819300919  This paper provides a comprehensive final report and extended analysis of the first shared task on End-to-End (E2E) Natural Language Generation (NLG), substantially extending previous reports (Novikova, Rieser, 2016, Novikova, Dušek, Rieser, 2017b, Dušek, Novikova, Rieser, 2018). 



Shang et al.(2015)  propose a Neural Responding Machine (NRM), a neural network-based
chatbot NLG for Short-Text Conversation, which is trained on a large amount of one-round conversation data collected from a microblogging service


 https://www.aclweb.org/anthology/N18-2010.pdf Previous work proposed
an RNNLM-based NLG (Wen et al., 2015) that
can be trained on any corpus of dialogue actutterance pairs without any semantic alignment
and hand-crafted features. Sequence-to-sequence
(seq2seq) generators (Cho et al., 2014; Sutskever
et al., 2014) further offer better results by leveraging encoder-decoder structure: previous model
encoded syntax trees and dialogue acts into sequences (Dusek and Jur ˇ cˇ´ıcek ˇ , 2016) as inputs of


http://primo.ai/index.php?title=Transformer

IMPORTANT: 
https://arxiv.org/pdf/1709.03010.pdf
https://www.aclweb.org/anthology/P17-4008.pdf

Li et al. (2016) defined a “persona” as the character that an artificial agent, as actor, plays or performs during conversational interactions.

architektura: 
emotional decoder 
https://link.springer.com/chapter/10.1007/978-3-319-73618-1_51
attentional seq2seq model (Bahdanau et al., 2015).



Cim se lisi: 
 prior studies are heavily dependent on linguistic tools or customized
parameters in text generation, while our model is fully datadriven without any manual adjustment;




check if it is used: 
@MISC{open_domain_neural_ds,
      author =       "Yun-Nung Chen and Jianfeng Gao",
      title =        "Open-Domain Neural Dialogue Systems",
      url =          "https://www.aclweb.org/anthology/I17-5003.pdf",
      note =         "[Online; visited 10.11.2019]"
    } 


@MISC{deep_learning_ds,
	author =	"Yun-Nung Chen and Asli Celikyilmaz and Dilek Hakkani-Tur",
	title =		"Deep Learning for Dialogue Systems",
	url = 		"https://www.aclweb.org/anthology/C18-3006.pdf",
	note = 		"[Online; visited 10.11.2019]"
	}



@MISC{applied_nlg,
	author =	"Ehud Reiter and Robert Dale",
	title =		"Building Applied Natural Language Generation",
	url = 		"https://pdfs.semanticscholar.org/728e/18fbf00f5a80e9a070db4f4416d66c7b28f4.pdf",
	note = 		"[Online; visited 17.11.2019]"
	}




@MISC{lstm_nlg,
	author =	"Tsung-Hsien Wen and  Milica Gašić and Nikola Mrkšić and Pei-Hao Su and David Vandyke and Steve Young",
	title =		"Semantically Conditioned LSTM-based Natural Language Generation for Spoken Dialogue Systems",
	url = 		"https://www.aclweb.org/anthology/D15-1199.pdf",
	note = 		"[Online; visited 24.11.2019]"
	}




Datasets: 
Twitter: Sordoni et al., 2015   which consists of 23 million conversational snippets randomly selected from a collection of 129M context-message-response triples

https://webscope.sandbox.yahoo.com/catalog.php?datatype=l Comprehensive Questions and Answers dataset


(DanescuNiculescu-Mizil and Lee, 2011 START WARS Cornell Movie-Dialogs Corpus

